{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"two_layer_net.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMYYAWEq/TJGxDQgBtkzeKG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"L-Xwb6jIpa0B","executionInfo":{"status":"ok","timestamp":1659009106854,"user_tz":-540,"elapsed":4,"user":{"displayName":"김기수","userId":"05232178571319528981"}},"outputId":"f26bc4b8-0a14-4c7f-fcec-d9a3f26d41ed","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((784, 100), (100,), (100, 10), (10,))"]},"metadata":{},"execution_count":2}],"source":["import numpy as np\n","\n","class TwoLayerNet:\n","    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n","        self.params = {}\n","        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","    def predict(self, x):\n","        W1, W2 = self.params['W1'], self.params['W2']\n","        b1, b2 = self.params['b1'], self.params['b2']\n","\n","        a1 = np.dot(x, W1) + b1\n","        z1 = sigmoid(a1)\n","        a2 = np.dot(x, W2) + b2\n","        z2 = sigmoid(a2)\n","        y = softmax(a2)\n","\n","        return y\n","\n","    def loss(self, x, t):\n","        y = self.predict(x)\n","        return cross_entropy_error(y, t)\n","\n","    def accuracy(self, x, t):\n","        y = self.predict(x)\n","        y = np.argmax(y, axis = 1)\n","        t = np.argmax(t, axis = 1)\n","\n","        accuracy = np.sum(y == t) / float(x.shape[0])\n","\n","        return accuracy\n","    \n","    def numerical_gradient(self, x, t):\n","        loss_W = lambda W : self.loss(x, t)\n","        grads = {}\n","        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n","        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n","        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n","        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n","\n","        return grads\n","\n","net = TwoLayerNet(input_size = 784, hidden_size = 100, output_size = 10)\n","net.params['W1'].shape, net.params['b1'].shape, net.params['W2'].shape, net.params['b2'].shape"]}]}