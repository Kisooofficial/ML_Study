{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-18T11:54:41.445784Z","iopub.execute_input":"2022-08-18T11:54:41.446821Z","iopub.status.idle":"2022-08-18T11:54:41.469637Z","shell.execute_reply.started":"2022-08-18T11:54:41.446775Z","shell.execute_reply":"2022-08-18T11:54:41.468507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#plotly.offline -> 내가 그린 그래프를 어디다가 표현할 것인지?\nimport plotly.offline as py\npy.init_notebook_mode(connected = True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\n                             GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold\n","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.471435Z","iopub.execute_input":"2022-08-18T11:54:41.472022Z","iopub.status.idle":"2022-08-18T11:54:41.493582Z","shell.execute_reply.started":"2022-08-18T11:54:41.471970Z","shell.execute_reply":"2022-08-18T11:54:41.492317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')\n\nPassengerId = test['PassengerId']\ntrain.head(3)\n\nfull_data = [train, test]\nprint(train.info())","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.494926Z","iopub.execute_input":"2022-08-18T11:54:41.495653Z","iopub.status.idle":"2022-08-18T11:54:41.534136Z","shell.execute_reply.started":"2022-08-18T11:54:41.495602Z","shell.execute_reply":"2022-08-18T11:54:41.532911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> Feature Engineering</h3>","metadata":{}},{"cell_type":"code","source":"print(train[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean())","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.537203Z","iopub.execute_input":"2022-08-18T11:54:41.537923Z","iopub.status.idle":"2022-08-18T11:54:41.553791Z","shell.execute_reply.started":"2022-08-18T11:54:41.537870Z","shell.execute_reply":"2022-08-18T11:54:41.552437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train[['Sex', 'Survived']].groupby(['Sex'], as_index = False).mean())","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.555711Z","iopub.execute_input":"2022-08-18T11:54:41.556261Z","iopub.status.idle":"2022-08-18T11:54:41.569168Z","shell.execute_reply.started":"2022-08-18T11:54:41.556219Z","shell.execute_reply":"2022-08-18T11:54:41.568192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n    \nprint(train[['FamilySize', 'Survived']].groupby(['FamilySize']).mean())","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.570492Z","iopub.execute_input":"2022-08-18T11:54:41.571053Z","iopub.status.idle":"2022-08-18T11:54:41.588087Z","shell.execute_reply.started":"2022-08-18T11:54:41.571016Z","shell.execute_reply":"2022-08-18T11:54:41.587077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"새로운 파생변수 생성 가능 => 혼자 왔는가? 아니면 가족이랑 같이 왔는가?<br>\n도메인 지식에 기반하면, 충분히 생각해볼 가치가 있는 부분임","metadata":{}},{"cell_type":"code","source":"for dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\nprint(train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index = False).mean())","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.589549Z","iopub.execute_input":"2022-08-18T11:54:41.590108Z","iopub.status.idle":"2022-08-18T11:54:41.605294Z","shell.execute_reply.started":"2022-08-18T11:54:41.590072Z","shell.execute_reply":"2022-08-18T11:54:41.604255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S') # 최반값으로 대체한거임\n\nprint(train[['Embarked', 'Survived']].groupby(['Embarked'], as_index = False).mean())","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.606761Z","iopub.execute_input":"2022-08-18T11:54:41.607355Z","iopub.status.idle":"2022-08-18T11:54:41.621246Z","shell.execute_reply.started":"2022-08-18T11:54:41.607316Z","shell.execute_reply":"2022-08-18T11:54:41.619946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\nprint(train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index = False).mean())","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.634435Z","iopub.execute_input":"2022-08-18T11:54:41.635116Z","iopub.status.idle":"2022-08-18T11:54:41.658077Z","shell.execute_reply.started":"2022-08-18T11:54:41.635074Z","shell.execute_reply":"2022-08-18T11:54:41.655857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Age 결측치 대체\nfor dataset in full_data:\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std,\n                                            size = age_null_count) #결측치를 되게 신박하게하네\n    \n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n    \ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\nprint(train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index = False).mean())","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.660709Z","iopub.execute_input":"2022-08-18T11:54:41.661445Z","iopub.status.idle":"2022-08-18T11:54:41.688922Z","shell.execute_reply.started":"2022-08-18T11:54:41.661392Z","shell.execute_reply":"2022-08-18T11:54:41.687776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_title(name):\n    title_search = re.search('([A-Za-z]+)\\.', name)\n    \n    if title_search:\n        return title_search.group(1) #첫번째 있는 내용을 가져오라는 것임\n    return \"\"\n\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n\nprint(pd.crosstab(train['Title'], train['Sex'])) #교차표 생성하는 거임","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.690481Z","iopub.execute_input":"2022-08-18T11:54:41.691605Z","iopub.status.idle":"2022-08-18T11:54:41.720545Z","shell.execute_reply.started":"2022-08-18T11:54:41.691525Z","shell.execute_reply":"2022-08-18T11:54:41.719655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col',\n                                                'Don', 'Dr', 'Major', 'Rev', 'Sir',\n                                                'Jonkheer', 'Dona'], 'Rare')\n    \n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \nprint(train[['Title', 'Survived']].groupby(['Title'], as_index = False).mean())","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.721745Z","iopub.execute_input":"2022-08-18T11:54:41.722362Z","iopub.status.idle":"2022-08-18T11:54:41.743111Z","shell.execute_reply.started":"2022-08-18T11:54:41.722327Z","shell.execute_reply":"2022-08-18T11:54:41.741903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in full_data:\n    dataset['Sex'] = dataset['Sex'].map({'female' : 0, 'male' : 1}).astype(int)\n    \n    title_mapping = {\"Mr\" : 1, \"Miss\" : 2, \"Mrs\" : 3, \"Master\" : 4, \"Rare\" : 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    dataset['Embarked'] = dataset['Embarked'].map({'S' : 0, 'C' : 1, 'Q' : 2}).astype(int)\n    \n    \n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']   \n    \n","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.746175Z","iopub.execute_input":"2022-08-18T11:54:41.746557Z","iopub.status.idle":"2022-08-18T11:54:41.781873Z","shell.execute_reply.started":"2022-08-18T11:54:41.746521Z","shell.execute_reply":"2022-08-18T11:54:41.780736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'FamilySize']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n\ntest = test.drop(drop_elements, axis = 1)\n\nprint(train.head(10))\n\ntrain = train.values\ntest = test.values","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.783122Z","iopub.execute_input":"2022-08-18T11:54:41.784098Z","iopub.status.idle":"2022-08-18T11:54:41.798205Z","shell.execute_reply.started":"2022-08-18T11:54:41.784058Z","shell.execute_reply":"2022-08-18T11:54:41.796672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(probability = True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()\n]\n\nlog_cols = ['Classifier', 'Accuracy']\nlog = pd.DataFrame(columns = log_cols)\n\nsss = StratifiedShuffleSplit(n_splits = 10, test_size = 0.1, random_state = 0)\n\nX = train[0::, 1::]\ny = train[0::, 0]\n\nacc_dict = {}\n\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    for clf in classifiers:\n        name = clf.__class__.__name__\n        clf.fit(X_train, y_train)\n        train_predictions = clf.predict(X_test)\n        acc = accuracy_score(y_test, train_predictions)\n        if name in acc_dict:\n            acc_dict[name] += acc\n        else:\n            acc_dict[name] = acc\n            \nfor clf in acc_dict:\n    acc_dict[clf] = acc_dict[clf] / 10.0\n    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns = log_cols)\n    log = log.append(log_entry)\n\n    \nplt.xlabel('Accuracy')\nplt.title('Classifier Accuracy')\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x = 'Accuracy', y = 'Classifier', data = log, color = 'b')","metadata":{"execution":{"iopub.status.busy":"2022-08-18T11:54:41.799585Z","iopub.execute_input":"2022-08-18T11:54:41.800857Z","iopub.status.idle":"2022-08-18T11:54:47.024045Z","shell.execute_reply.started":"2022-08-18T11:54:41.800817Z","shell.execute_reply":"2022-08-18T11:54:47.022990Z"},"trusted":true},"execution_count":null,"outputs":[]}]}